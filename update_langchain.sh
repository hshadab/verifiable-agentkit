#!/bin/bash
# update_langchain.sh - Drop-in script to fix AI content authenticity recognition

set -e

LANGCHAIN_FILE="langchain_service.py"
BACKUP_FILE="langchain_service.py.backup"

echo "ğŸ”§ Updating LangChain service to support AI content authenticity..."

# Create backup
if [ ! -f "$BACKUP_FILE" ]; then
    echo "ğŸ“ Creating backup: $BACKUP_FILE"
    cp "$LANGCHAIN_FILE" "$BACKUP_FILE"
else
    echo "âš ï¸  Backup already exists, skipping backup creation"
fi

# Create the updated file using Python
cat > update_langchain.py << 'EOFPYTHON'
import re

# Read the current file
with open('langchain_service.py', 'r') as f:
    content = f.read()

# 1. Update SYSTEM_PROMPT to include prove_ai_content function
old_system_prompt = """Available proof functions:
1. prove_location(city, device_id) - Prove device location within city boundaries (San Francisco, New York, London)
2. fibonacci(n) - Prove the nth Fibonacci number"""

new_system_prompt = """Available proof functions:
1. prove_ai_content(content_type, verification_method) - Prove AI-generated content authenticity and integrity
2. prove_location(city, device_id) - Prove device location within city boundaries (San Francisco, New York, London)
3. fibonacci(n) - Prove the nth Fibonacci number"""

content = content.replace(old_system_prompt, new_system_prompt)

# Add AI content examples to system prompt
ai_examples = '''AI CONTENT PROOF EXAMPLES:
- "prove ai content authenticity" â†’ Generate authenticity proof for AI-generated content
- "verify ai generated content" â†’ Prove content was generated by AI and hasn't been tampered with
- "ai content verification" â†’ Create cryptographic proof of AI content integrity

When users request AI content proofs, you should:
1. Generate the proof intent with prove_ai_content function
2. Explain how zero-knowledge proofs can verify AI content without revealing the content itself
3. Describe applications in content verification, deepfake detection, and AI model attestation
4. Mention use cases in media authenticity and digital provenance

LOCATION PROOF EXAMPLES:'''

content = content.replace('LOCATION PROOF EXAMPLES:', ai_examples)

# 2. Update the patterns dictionary in extract_proof_intent function
old_patterns = '''    # Pattern matching for mathematical functions
    patterns = {
        'fibonacci': ['''

new_patterns = '''    # Pattern matching for ALL functions including AI content
    patterns = {
        'prove_ai_content': [
            r'prove\\s+ai\\s+content\\s+authenticity',
            r'ai\\s+content\\s+authenticity', 
            r'verify\\s+ai\\s+content',
            r'prove\\s+content\\s+authenticity',
            r'ai\\s+authenticity',
            r'content\\s+verification',
            r'verify\\s+ai\\s+generated',
            r'prove\\s+ai\\s+generated',
            r'ai\\s+content\\s+proof',
            r'authenticate\\s+ai\\s+content',
            r'ai\\s+content',
            r'content\\s+authenticity'
        ],
        'fibonacci': ['''

content = content.replace(old_patterns, new_patterns)

# 3. Update the pattern matching logic to handle functions without capture groups
old_pattern_logic = '''    for func, func_patterns in patterns.items():
        for pattern in func_patterns:
            match = re.search(pattern, message_lower)
            if match:
                args = list(match.groups())
                step_size, _ = analyze_proof_complexity(func, args, custom_step_size)
                return {
                    'function': func,
                    'arguments': args,
                    'step_size': step_size,
                    'custom_step_size': custom_step_size is not None
                }'''

new_pattern_logic = '''    for func, func_patterns in patterns.items():
        for pattern in func_patterns:
            match = re.search(pattern, message_lower)
            if match:
                # Handle functions with no capture groups (like prove_ai_content)
                if match.groups():
                    args = list(match.groups())
                else:
                    # For AI content, use default arguments
                    if func == 'prove_ai_content':
                        args = ["default_content", "authenticity_check"]
                    else:
                        args = []
                
                step_size, _ = analyze_proof_complexity(func, args, custom_step_size)
                return {
                    'function': func,
                    'arguments': args,
                    'step_size': step_size,
                    'custom_step_size': custom_step_size is not None
                }'''

content = content.replace(old_pattern_logic, new_pattern_logic)

# 4. Update analyze_proof_complexity function
old_complexity = '''        elif function == "prove_location":
            return (50, f"Location proof for DePIN network.")
        else:
            return (50, f"Simple operation: {function}.")'''

new_complexity = '''        elif function == "prove_location":
            return (50, f"Location proof for DePIN network.")
        elif function == "prove_ai_content":
            return (50, f"AI content authenticity proof with verification method: {args[1] if len(args) > 1 else 'default'}.")
        else:
            return (50, f"Simple operation: {function}.")'''

content = content.replace(old_complexity, new_complexity)

# 5. Update step size information in system prompt
old_step_info = '''  * Medium complexity (factorial < 10, fibonacci < 15): 50'''
new_step_info = '''  * Medium complexity (factorial < 10, fibonacci < 15, prove_ai_content): 50'''

content = content.replace(old_step_info, new_step_info)

# Write the updated file
with open('langchain_service.py', 'w') as f:
    f.write(content)

print("âœ… Successfully updated langchain_service.py")
EOFPYTHON

# Run the Python update script
echo "ğŸ Running Python update script..."
python3 update_langchain.py

# Clean up the update script
rm update_langchain.py

# Update Rust backend to handle prove_ai_content
if [ -f "src/main.rs" ]; then
    echo "ğŸ“ Creating Rust backup: src/main.rs.backup"
    cp src/main.rs src/main.rs.backup
    
    # Add prove_ai_content mapping to Rust code
    sed -i 's/"count_until" => "count_until.wat",/"count_until" => "count_until.wat",\n                    "prove_ai_content" => "prove_ai_content.wat",/' src/main.rs
    
    if grep -q "prove_ai_content" src/main.rs; then
        echo "âœ… Rust backend updated successfully"
    else
        echo "âŒ Failed to update Rust backend automatically"
        echo "   Manually add this line to src/main.rs in the wasm_file match statement:"
        echo "   \"prove_ai_content\" => \"prove_ai_content.wat\","
    fi
else
    echo "âŒ src/main.rs not found. Make sure you're in the agentkit directory."
fi

# Verify the changes
echo "ğŸ” Verifying changes..."
if grep -q "prove_ai_content" "$LANGCHAIN_FILE"; then
    echo "âœ… AI content patterns added successfully"
else
    echo "âŒ Error: AI content patterns not found after update"
    exit 1
fi

echo ""
echo "ğŸ‰ LangChain service updated successfully!"
echo "âœ… prove_ai_content.wat file already exists!"
echo ""
echo "ğŸ“‹ Next steps:"
echo "1. Restart your services:"
echo "   sudo lsof -ti:8001 | xargs kill -9"
echo "   sudo lsof -ti:8002 | xargs kill -9"
echo "   cargo run &"
echo "   source langchain_env/bin/activate && python langchain_service.py &"
echo ""
echo "2. Test with: 'prove ai content authenticity'"
echo ""
echo "ğŸ’¾ Backup saved as: $BACKUP_FILE"
