#!/usr/bin/env python3
"""
FIXED Integrated LangChain + Transform Service for zkEngine
Fixed WAT generation for custom proofs
"""

from fastapi import FastAPI, HTTPException, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any, Union, Tuple
import os
import re
import subprocess
import tempfile
import uuid
from datetime import datetime
import json
import random
import shutil

from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.output_parsers import PydanticOutputParser
from langchain.memory import ConversationBufferMemory
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from langchain.chains import LLMChain
from langchain.schema.runnable import RunnablePassthrough

app = FastAPI(title="zkEngine Integrated Service - FIXED WAT Generation")

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ===== MODELS (unchanged) =====

class ProofIntent(BaseModel):
    """Structured output for proof generation intent"""
    function: str = Field(description="The proof function to call: prove_kyc, prove_ai_content, prove_location")
    arguments: List[str] = Field(description="Arguments for the function as strings")
    step_size: int = Field(description="Computation steps: 50 for all current proof types")
    explanation: str = Field(description="Human-friendly explanation of what will be proved")
    complexity_reasoning: Optional[str] = Field(description="Why this step size was chosen")
    additional_context: Optional[Dict[str, Any]] = Field(description="Additional context or insights", default={})

class ChatRequest(BaseModel):
    message: str
    session_id: Optional[str] = "default"
    context: Optional[Dict[str, Any]] = None

class ChatResponse(BaseModel):
    intent: Optional[ProofIntent] = None
    response: str
    session_id: str
    requires_proof: bool = False
    additional_analysis: Optional[str] = None
    suggestions: Optional[List[str]] = None

class TransformRequest(BaseModel):
    code: str
    auto_transform: bool = True

class TransformResponse(BaseModel):
    success: bool
    transformed_code: str
    changes: List[str]
    error: Optional[str] = None

class CompileRequest(BaseModel):
    code: str
    filename: str

class CompileResponse(BaseModel):
    success: bool
    wat_content: Optional[str] = None
    wasm_file: Optional[str] = None
    wasm_size: Optional[int] = None
    error: Optional[str] = None

# Initialize LangChain components
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    print("WARNING: OPENAI_API_KEY not found in environment variables!")

llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0.7,
    api_key=api_key
)

# Memory storage per session
memory_store: Dict[str, ConversationBufferMemory] = {}

# Streamlined system prompt (unchanged)
SYSTEM_PROMPT = """You are an intelligent assistant for zkEngine, a zero-knowledge proof system..."""

# ===== TRANSFORM SERVICE FUNCTIONS =====

def transform_for_zkengine(code: str) -> Tuple[str, List[str]]:
    """Auto-transforms normal C to zkEngine-compatible code"""
    changes = []
    
    # Add stdint.h if not present and we're using int32_t
    if 'int32_t' not in code and ('int ' in code or 'float ' in code):
        if '#include <stdint.h>' not in code:
            include_pos = code.rfind('#include')
            if include_pos >= 0:
                newline_pos = code.find('\n', include_pos)
                if newline_pos >= 0:
                    code = code[:newline_pos+1] + '#include <stdint.h>\n' + code[newline_pos+1:]
                else:
                    code = code + '\n#include <stdint.h>\n'
            else:
                code = '#include <stdint.h>\n\n' + code
            changes.append("Added #include <stdint.h>")
    
    # Type conversions
    code = re.sub(r'\bint\s+', 'int32_t ', code)
    code = re.sub(r'\bfloat\s+', 'int32_t ', code)
    changes.append("Converted int/float to int32_t")
    
    # Remove I/O operations
    if 'printf' in code:
        code = re.sub(r'printf\s*\([^;]+\);', '/* printf removed */;', code)
        changes.append("Removed printf statements")
    
    if 'scanf' in code:
        code = re.sub(r'scanf\s*\([^;]+\);', '/* scanf removed */;', code)
        changes.append("Removed scanf statements")
    
    # Fix main function for hardcoded values
    # Since values are now hardcoded, main doesn't need parameters
    main_match = re.search(r'int32_t\s+main\s*\([^)]*\)', code)
    if main_match:
        # Replace with parameterless main
        code = re.sub(r'int32_t\s+main\s*\([^)]*\)', 'int32_t main()', code)
        changes.append("Fixed main signature for hardcoded values")
    
    # Convert malloc to stack allocations
    if 'malloc' in code:
        if '#define BUFFER_SIZE' not in code:
            includes_end = 0
            for match in re.finditer(r'#include\s*<[^>]+>', code):
                includes_end = match.end()
            
            if includes_end > 0:
                code = code[:includes_end] + '\n#define BUFFER_SIZE 1000\n' + code[includes_end:]
            else:
                code = '#define BUFFER_SIZE 1000\n' + code
        
        code = re.sub(r'(\w+)\s*=\s*malloc\([^)]+\)', r'\1 = (int32_t*)stack_buffer', code)
        code = re.sub(r'free\s*\([^)]+\);', '/* free removed */;', code)
        
        main_start = code.find('{', code.find('main'))
        if main_start > 0:
            code = code[:main_start+1] + '\n    int32_t stack_buffer[BUFFER_SIZE];\n' + code[main_start+1:]
        
        changes.append("Converted dynamic allocation to stack")
    
    return code, changes

def generate_wat_from_c_analysis(code: str) -> str:
    """Generate WAT based on C code analysis for common patterns"""
    
    # Check for is_prime pattern
    if 'is_prime' in code:
        # Extract the hardcoded value if present
        value_match = re.search(r'number_to_check\s*=\s*(\d+)', code)
        if value_match:
            return f"""(module
  ;; Prime checker - hardcoded value: {value_match.group(1)}
  (func $is_prime (param $n i32) (result i32)
    (local $i i32)
    
    ;; if n <= 1 return 0
    local.get $n
    i32.const 1
    i32.le_s
    if (result i32)
      i32.const 0
      return
    end
    
    ;; if n == 2 return 1
    local.get $n
    i32.const 2
    i32.eq
    if (result i32)
      i32.const 1
      return
    end
    
    ;; if n % 2 == 0 return 0
    local.get $n
    i32.const 2
    i32.rem_s
    i32.eqz
    if (result i32)
      i32.const 0
      return
    end
    
    ;; Check odd divisors
    i32.const 3
    local.set $i
    
    loop $check_loop
      ;; if i * i > n, break (number is prime)
      local.get $i
      local.get $i
      i32.mul
      local.get $n
      i32.gt_s
      br_if 1
      
      ;; if n % i == 0 return 0
      local.get $n
      local.get $i
      i32.rem_s
      i32.eqz
      if (result i32)
        i32.const 0
        return
      end
      
      ;; i += 2
      local.get $i
      i32.const 2
      i32.add
      local.set $i
      
      br $check_loop
    end
    
    ;; Number is prime
    i32.const 1
  )
  
  (func $main (export "main") (result i32)
    ;; Call is_prime with hardcoded value
    i32.const {value_match.group(1) if value_match else '17'}
    call $is_prime
  )
)"""
    
    # Check for collatz pattern
    elif 'collatz' in code:
        value_match = re.search(r'starting_number\s*=\s*(\d+)', code)
        return f"""(module
  ;; Collatz steps calculator - hardcoded value: {value_match.group(1) if value_match else '27'}
  (func $collatz_steps (param $n i32) (result i32)
    (local $steps i32)
    (local $current i32)
    
    ;; Initialize
    local.get $n
    local.set $current
    i32.const 0
    local.set $steps
    
    ;; Ensure positive
    local.get $current
    i32.const 0
    i32.le_s
    if
      i32.const 1
      local.set $current
    end
    
    ;; Main loop
    loop $collatz_loop
      ;; If n == 1, done
      local.get $current
      i32.const 1
      i32.eq
      br_if 1
      
      ;; Safety check: steps < 1000
      local.get $steps
      i32.const 1000
      i32.ge_s
      br_if 1
      
      ;; Apply Collatz rules
      local.get $current
      i32.const 2
      i32.rem_s
      i32.eqz
      if
        ;; Even: n / 2
        local.get $current
        i32.const 2
        i32.div_s
        local.set $current
      else
        ;; Odd: 3n + 1
        local.get $current
        i32.const 3
        i32.mul
        i32.const 1
        i32.add
        local.set $current
      end
      
      ;; Increment steps
      local.get $steps
      i32.const 1
      i32.add
      local.set $steps
      
      br $collatz_loop
    end
    
    local.get $steps
  )
  
  (func $main (export "main") (result i32)
    ;; Call with hardcoded value
    i32.const {value_match.group(1) if value_match else '27'}
    call $collatz_steps
  )
)"""
    
    # Check for digital root pattern
    elif 'digital_root' in code or 'digit_sum' in code:
        value_match = re.search(r'input_number\s*=\s*(\d+)', code)
        return f"""(module
  ;; Digital root calculator - hardcoded value: {value_match.group(1) if value_match else '12345'}
  (func $digit_sum (param $n i32) (result i32)
    (local $sum i32)
    (local $num i32)
    
    ;; Make positive
    local.get $n
    i32.const 0
    i32.lt_s
    if
      local.get $n
      i32.const -1
      i32.mul
      local.set $num
    else
      local.get $n
      local.set $num
    end
    
    ;; Sum digits
    i32.const 0
    local.set $sum
    
    loop $sum_loop
      local.get $num
      i32.eqz
      br_if 1
      
      ;; sum += num % 10
      local.get $sum
      local.get $num
      i32.const 10
      i32.rem_s
      i32.add
      local.set $sum
      
      ;; num /= 10
      local.get $num
      i32.const 10
      i32.div_s
      local.set $num
      
      br $sum_loop
    end
    
    local.get $sum
  )
  
  (func $digital_root (param $n i32) (result i32)
    (local $current i32)
    
    local.get $n
    local.set $current
    
    loop $root_loop
      local.get $current
      i32.const 10
      i32.lt_s
      br_if 1
      
      local.get $current
      call $digit_sum
      local.set $current
      
      br $root_loop
    end
    
    local.get $current
  )
  
  (func $main (export "main") (result i32)
    ;; Call with hardcoded value
    i32.const {value_match.group(1) if value_match else '12345'}
    call $digital_root
  )
)"""
    
    # Default simple WAT
    else:
        return """(module
  (func $main (export "main") (result i32)
    i32.const 42
  )
)"""

async def compile_to_wasm(code: str, filename: str) -> Dict[str, Any]:
    """Compile transformed C code to WebAssembly TEXT format"""
    try:
        # Create temporary directory
        with tempfile.TemporaryDirectory() as tmpdir:
            # Generate unique filename
            base_name = filename.replace('.c', '')
            unique_id = str(uuid.uuid4())[:8]
            c_file = os.path.join(tmpdir, f"{base_name}_{unique_id}.c")
            wasm_file = os.path.join(tmpdir, f"{base_name}_{unique_id}.wasm")
            wat_file = os.path.join(tmpdir, f"{base_name}_{unique_id}.wat")
            
            # Write C code
            with open(c_file, 'w') as f:
                f.write(code)
            
            # Try to compile to WASM using clang
            compile_cmd = [
                'clang',
                '--target=wasm32',
                '-nostdlib',
                '-Wl,--no-entry',
                '-Wl,--export-all',
                '-o', wasm_file,  # Output as .wasm first
                c_file
            ]
            
            result = subprocess.run(compile_cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                # Try to convert to WAT using wasm2wat
                try:
                    wat_cmd = ['wasm2wat', wasm_file, '-o', wat_file]
                    wat_result = subprocess.run(wat_cmd, capture_output=True, text=True)
                    
                    if wat_result.returncode == 0:
                        # Read the WAT content
                        with open(wat_file, 'r') as f:
                            wat_content = f.read()
                    else:
                        raise Exception(f"wasm2wat failed: {wat_result.stderr}")
                        
                except FileNotFoundError:
                    # wasm2wat not installed, generate WAT from code analysis
                    print("wasm2wat not found, generating WAT from code analysis")
                    wat_content = generate_wat_from_c_analysis(code)
                    with open(wat_file, 'w') as f:
                        f.write(wat_content)
                        
            else:
                # Compilation failed, generate simple WAT
                print(f"Clang compilation failed: {result.stderr}")
                wat_content = generate_wat_from_c_analysis(code)
                with open(wat_file, 'w') as f:
                    f.write(wat_content)
            
            # Copy to zkEngine wasm directory
            wasm_dir = os.path.expanduser('~/agentkit/zkengine/example_wasms')
            os.makedirs(wasm_dir, exist_ok=True)
            
            final_wat_name = f"{base_name}_{unique_id}.wat"
            final_wat_path = os.path.join(wasm_dir, final_wat_name)
            
            # Ensure we write text WAT content
            with open(final_wat_path, 'w') as f:
                f.write(wat_content)
            
            # Get file size
            file_size = len(wat_content.encode('utf-8'))
            
            return {
                'success': True,
                'wat_content': wat_content,
                'wasm_file': final_wat_name,
                'wasm_size': file_size
            }
            
    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }

# ===== LANGCHAIN FUNCTIONS (unchanged) =====

def get_memory(session_id: str) -> ConversationBufferMemory:
    if session_id not in memory_store:
        memory_store[session_id] = ConversationBufferMemory(
            return_messages=True,
            memory_key="history"
        )
    return memory_store[session_id]

def analyze_proof_complexity(function: str, args: List[str], custom_step_size: Optional[int] = None) -> Tuple[int, str]:
    """Analyze the computational complexity of a proof request"""
    if custom_step_size:
        if custom_step_size < 10:
            return (50, f"Custom step size {custom_step_size} too low, using minimum 50.")
        elif custom_step_size > 10000:
            return (1000, f"Custom step size {custom_step_size} too high, capping at 1000.")
        else:
            return (custom_step_size, f"Using custom step size: {custom_step_size}")
    
    if function == "prove_location":
        return (50, f"Location proof for DePIN network.")
    elif function == "prove_kyc":
        return (50, f"Circle KYC compliance proof with wallet_hash: {args[0] if len(args) > 0 else '12345'}, kyc_status: {args[1] if len(args) > 1 else '1'} (1=approved).")
    elif function == "prove_ai_content":
        return (50, f"AI content authenticity proof with content_hash: {args[0] if len(args) > 0 else '42'}, auth_type: {args[1] if len(args) > 1 else '1'}.")
    else:
        return (50, f"Simple operation: {function}.")

def extract_proof_intent(message: str) -> Optional[Dict[str, Any]]:
    """Extract proof intent from message using pattern matching"""
    message_lower = message.lower()
    
    # LOCATION PATTERNS FIRST - highest priority
    if 'location' in message_lower:
        cities = ['san francisco', 'sf', 'new york', 'nyc', 'london']
        detected_city = None
        for city in cities:
            if city in message_lower:
                detected_city = city
                break
        
        if detected_city:
            device_match = re.search(r'device.*?(\d+)', message_lower)
            device_id = device_match.group(1) if device_match else str(random.randint(1000, 99999))
            
            return {
                'function': 'prove_location',
                'arguments': [detected_city, device_id],
                'step_size': 50,
                'location_based': True
            }
    
    # Check for custom step size specification
    custom_step_size = None
    step_size_patterns = [
        r'(?:with\s+)?step\s+size\s+(\d+)',
        r'(?:using\s+)?(\d+)\s+step\s+size',
        r'step\s+(\d+)',
    ]
    
    for pattern in step_size_patterns:
        match = re.search(pattern, message_lower)
        if match:
            custom_step_size = int(match.group(1))
            break
    
    # Pattern matching for 3 main proof types
    patterns = {
        'prove_kyc': [
            r'prove\s+kyc\s+compliance',
            r'kyc\s+compliance',
            r'verify\s+kyc\s+status',
            r'prove\s+kyc',
            r'kyc\s+proof',
            r'kyc\s+verification',
            r'circle\s+kyc',
            r'regulatory\s+compliance',
            r'compliance\s+proof',
            r'kyc\s+approved',
            r'prove\s+compliance'
        ],
        'prove_ai_content': [
            r'prove\s+ai\s+content\s+authenticity',
            r'ai\s+content\s+authenticity', 
            r'verify\s+ai\s+content',
            r'prove\s+content\s+authenticity',
            r'ai\s+authenticity',
            r'content\s+verification',
            r'verify\s+ai\s+generated',
            r'prove\s+ai\s+generated',
            r'ai\s+content\s+proof',
            r'authenticate\s+ai\s+content',
            r'ai\s+content',
            r'content\s+authenticity'
        ]
    }
    
    for func, func_patterns in patterns.items():
        for pattern in func_patterns:
            match = re.search(pattern, message_lower)
            if match:
                # Handle functions with no capture groups
                if match.groups():
                    args = list(match.groups())
                else:
                    # Set default arguments for each proof type
                    if func == 'prove_kyc':
                        args = ["12345", "1"]  # wallet_hash=12345, kyc_approved=1
                    elif func == 'prove_ai_content':
                        args = ["42", "1"]  # content_hash=42, auth_type=1
                    else:
                        args = []
                
                step_size, _ = analyze_proof_complexity(func, args, custom_step_size)
                return {
                    'function': func,
                    'arguments': args,
                    'step_size': step_size,
                    'custom_step_size': custom_step_size is not None
                }
    
    return None

# ===== API ENDPOINTS =====

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """Process natural language and return structured proof intent with rich contextual response"""
    try:
        memory = get_memory(request.session_id)
        
        # First, check if this might involve a proof or verification
        lower_msg = request.message.lower()
        
        # Check for verification requests
        is_verification = any(word in lower_msg for word in ["verify", "check", "validate"])
        
        # Check for proof-related content
        proof_intent = extract_proof_intent(request.message)
        
        # Determine if additional context is requested
        has_language_request = any(lang in lower_msg for lang in [
            "spanish", "espa√±ol", "french", "fran√ßais", "german", "deutsch",
            "italian", "italiano", "portuguese", "portugu√™s", "chinese", "‰∏≠Êñá",
            "japanese", "Êó•Êú¨Ë™û", "russian", "—Ä—É—Å—Å–∫–∏–π", "arabic", "ÿπÿ±ÿ®Ÿä",
            "persian", "farsi", "ŸÅÿßÿ±ÿ≥€å"
        ])
        
        has_analysis_request = any(word in lower_msg for word in [
            "explain", "market", "trends", "analysis", "significance",
            "philosophy", "cultural", "economic", "business", "industry",
            "what is", "tell me", "describe"
        ])
        
        # If we have a proof intent OR special request, process with LLM
        if proof_intent or has_language_request or has_analysis_request or is_verification:
            # Build the enhanced prompt
            enhanced_prompt = ChatPromptTemplate.from_messages([
                ("system", SYSTEM_PROMPT),
                MessagesPlaceholder(variable_name="history"),
                ("human", "{input}"),
                ("system", """Analyze this request carefully. The user said: "{input}"

ABSOLUTELY CRITICAL: 
- Use ONLY plain text
- NO markdown formatting whatsoever
- NO asterisks, hashtags, backticks, underscores, or any other formatting symbols
- Write everything as simple, clean plain text

If they're asking for a proof (kyc, ai content, location), extract these details:
- Function name
- Arguments
- Provide a rich explanation in the language they requested

If they're asking for verification:
- Acknowledge the verification request
- Explain what proof verification means
- Let them know the system will verify the proof
- DO NOT say you cannot verify proofs

Always provide a conversational, helpful response that addresses ALL aspects of their request.
If they ask in a specific language, respond in that language (except technical terms).""")
            ])
            
            # Get conversation history
            messages = memory.chat_memory.messages
            
            # Create the prompt
            prompt_value = enhanced_prompt.format_prompt(
                input=request.message,
                history=messages
            )
            
            # Get LLM response
            response = llm.invoke(prompt_value.to_messages())
            response_content = response.content
            
            # Clean any remaining markdown that might slip through
            response_content = re.sub(r'\*+', '', response_content)
            response_content = re.sub(r'#+', '', response_content)
            response_content = re.sub(r'`+', '', response_content)
            response_content = re.sub(r'_+', '', response_content)
            response_content = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', response_content)
            
            # Initialize response components
            intent = None
            requires_proof = False
            main_response = response_content
            
            # If we detected a proof intent, create the structured intent
            if proof_intent:
                step_size, complexity_reasoning = analyze_proof_complexity(
                    proof_intent['function'], 
                    proof_intent['arguments'],
                    proof_intent.get('step_size') if proof_intent.get('custom_step_size') else None
                )
                
                explanation = f"Generating proof for {proof_intent['function']}({', '.join(proof_intent['arguments'])})"
                if proof_intent.get('custom_step_size'):
                    explanation += f" with custom step size {step_size}"
                
                intent = ProofIntent(
                    function=proof_intent['function'],
                    arguments=proof_intent['arguments'],
                    step_size=step_size,
                    explanation=explanation,
                    complexity_reasoning=complexity_reasoning
                )
                requires_proof = True
            
            # Save to memory
            memory.save_context(
                {"input": request.message},
                {"output": main_response}
            )
            
            return ChatResponse(
                intent=intent,
                response=main_response,
                session_id=request.session_id,
                requires_proof=requires_proof
            )
        
        else:
            # For non-proof queries, still use LLM for natural conversation
            conversation_prompt = ChatPromptTemplate.from_messages([
                ("system", SYSTEM_PROMPT + "\n\nThe user is having a general conversation. Be helpful and conversational. Remember: NO markdown formatting whatsoever. Use only plain text."),
                MessagesPlaceholder(variable_name="history"),
                ("human", "{input}")
            ])
            
            # Use invoke method
            chain = conversation_prompt | llm
            
            # Get history
            messages = memory.chat_memory.messages
            
            # Invoke the chain
            response = chain.invoke({
                "input": request.message,
                "history": messages
            })
            
            # Clean any markdown from response
            cleaned_content = response.content
            cleaned_content = re.sub(r'\*+', '', cleaned_content)
            cleaned_content = re.sub(r'#+', '', cleaned_content)
            cleaned_content = re.sub(r'`+', '', cleaned_content)
            cleaned_content = re.sub(r'_+', '', cleaned_content)
            cleaned_content = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', cleaned_content)
            
            # Save to memory
            memory.save_context(
                {"input": request.message},
                {"output": cleaned_content}
            )
            
            return ChatResponse(
                intent=None,
                response=cleaned_content,
                session_id=request.session_id or "default",
                requires_proof=False
            )
        
    except Exception as e:
        print(f"Error in chat endpoint: {e}")
        import traceback
        traceback.print_exc()
        
        # Return a helpful error response
        return ChatResponse(
            intent=None,
            response=f"I understand you're asking about: {request.message}. Let me help you with that. Could you please rephrase your request or try one of the examples from the sidebar?",
            session_id=request.session_id or "default",
            requires_proof=False
        )

@app.get("/sessions/{session_id}/history")
async def get_history(session_id: str):
    """Get conversation history for a session"""
    if session_id in memory_store:
        memory = memory_store[session_id]
        messages = memory.chat_memory.messages
        return {
            "session_id": session_id,
            "messages": [
                {
                    "type": type(msg).__name__,
                    "content": msg.content
                }
                for msg in messages
            ]
        }
    return {"session_id": session_id, "messages": []}

@app.delete("/sessions/{session_id}")
async def clear_session(session_id: str):
    """Clear conversation history for a session"""
    if session_id in memory_store:
        del memory_store[session_id]
    return {"message": f"Session {session_id} cleared"}

@app.get("/health")
async def health():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "service": "integrated",
        "model": "gpt-4o-mini",
        "active_sessions": len(memory_store),
        "features": [
            "multilingual", 
            "market_analysis", 
            "educational_content", 
            "kyc_proofs", 
            "ai_content_proofs", 
            "location_proofs",
            "code_transformation",
            "wasm_compilation"
        ]
    }

@app.post("/analyze")
async def analyze_concept(request: Dict[str, str]):
    """Analyze a mathematical concept with market and philosophical perspectives"""
    concept = request.get("concept", "")
    domain = request.get("domain", "general")
    language = request.get("language", "english")
    
    analysis_prompt = ChatPromptTemplate.from_template("""
    Analyze the concept: {concept}
    Domain focus: {domain}
    Response language: {language}
    
    CRITICAL: Use ONLY plain text. NO markdown formatting. No asterisks, hashtags, backticks, or any other formatting.
    
    Provide:
    1. A clear explanation of the concept
    2. How it relates to zkEngine proofs and zero-knowledge systems
    3. Domain-specific insights ({domain})
    4. Suggested proofs to demonstrate this concept
    5. Real-world applications and implications
    
    Make the analysis engaging and accessible while maintaining technical accuracy.
    If the language is not English, provide the entire response in {language}.
    """)
    
    response = llm.invoke(analysis_prompt.format(
        concept=concept,
        domain=domain,
        language=language
    ))
    
    # Clean any markdown that might appear
    cleaned_content = response.content
    cleaned_content = re.sub(r'\*+', '', cleaned_content)
    cleaned_content = re.sub(r'#+', '', cleaned_content)
    cleaned_content = re.sub(r'`+', '', cleaned_content)
    cleaned_content = re.sub(r'_+', '', cleaned_content)
    cleaned_content = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', cleaned_content)
    
    return {
        "concept": concept,
        "domain": domain,
        "language": language,
        "analysis": cleaned_content
    }

# ===== TRANSFORM SERVICE ENDPOINTS =====

@app.post("/api/transform-code", response_model=TransformResponse)
async def transform_code(request: TransformRequest):
    """Transform C code to zkEngine-compatible format"""
    try:
        if request.auto_transform:
            transformed_code, changes = transform_for_zkengine(request.code)
            return TransformResponse(
                success=True,
                transformed_code=transformed_code,
                changes=changes
            )
        else:
            return TransformResponse(
                success=True,
                transformed_code=request.code,
                changes=["No transformation applied (auto_transform=False)"]
            )
    except Exception as e:
        return TransformResponse(
            success=False,
            transformed_code=request.code,
            changes=[],
            error=str(e)
        )

@app.post("/api/compile-transformed", response_model=CompileResponse)
async def compile_transformed(request: CompileRequest):
    """Compile transformed C code to WebAssembly TEXT format"""
    try:
        result = await compile_to_wasm(request.code, request.filename)
        
        if result['success']:
            return CompileResponse(
                success=True,
                wat_content=result.get('wat_content'),
                wasm_file=result.get('wasm_file'),
                wasm_size=result.get('wasm_size')
            )
        else:
            return CompileResponse(
                success=False,
                error=result.get('error', 'Unknown compilation error')
            )
    except Exception as e:
        return CompileResponse(
            success=False,
            error=str(e)
        )

# Upload interface endpoint (optional)
@app.get("/upload")
async def upload_interface():
    """Simple upload interface for testing"""
    html_content = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>zkEngine Code Upload</title>
        <style>
            body { font-family: Arial; margin: 40px; background: #0a0a0a; color: #e2e8f0; }
            .container { max-width: 800px; margin: 0 auto; }
            h1 { color: #c084fc; }
            .info { background: rgba(139, 92, 246, 0.1); padding: 20px; border-radius: 8px; margin: 20px 0; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>zkEngine Code Upload</h1>
            <div class="info">
                <p>The upload functionality is integrated into the main UI.</p>
                <p>Use the üì§ button next to the input field in the main interface.</p>
                <p>Or use the üìã paste button to paste C code directly.</p>
            </div>
            <a href="http://localhost:8001" style="color: #a78bfa;">‚Üê Back to Main Interface</a>
        </div>
    </body>
    </html>
    """
    return HTMLResponse(content=html_content)

if __name__ == "__main__":
    import uvicorn
    print("üöÄ Starting FIXED Integrated zkEngine Service on port 8002...")
    print("Features enabled:")
    print("‚úì Natural language processing with GPT-4o-mini")
    print("‚úì Circle KYC compliance proofs")
    print("‚úì AI content authenticity proofs")
    print("‚úì DePIN location proofs")
    print("‚úì C code transformation to zkEngine format")
    print("‚úì WebAssembly TEXT (WAT) compilation - FIXED!")
    print("‚úì Hardcoded value support for paste examples")
    print("‚úì Multilingual support")
    print("‚úì Educational content generation")
    print("\nNo need for separate transform service anymore! üéâ")
    uvicorn.run(app, host="0.0.0.0", port=8002)
